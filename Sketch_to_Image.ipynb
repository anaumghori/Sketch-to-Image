{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "11SbTO5LAg8lk9eVTX-248Zu230P9-oEz",
      "authorship_tag": "ABX9TyPpfQbHSNRR3ypDMODa5jTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaumghori/Sketch-to-Image/blob/main/Sketch_to_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirements**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LTC_VwCDg83_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio controlnet_aux transformers torchvision mediapipe xformers diffusers"
      ],
      "metadata": {
        "id": "3CjMp44PlHdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import necessary Libraries and Models**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qih5nwpsiBQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL\n",
        "from diffusers import EulerAncestralDiscreteScheduler\n",
        "from controlnet_aux import HEDdetector\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Dnl_4KEHg9J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"xinsir/controlnet-scribble-sdxl-1.0\", torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16).to(device)\n",
        "scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"scheduler\")\n",
        "\n",
        "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet=controlnet,\n",
        "    vae=vae,\n",
        "    safety_checker=None,\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=scheduler,\n",
        ").to(device)\n",
        "\n",
        "hed_processor = HEDdetector.from_pretrained(\"lllyasviel/Annotators\")"
      ],
      "metadata": {
        "id": "VxyH8XpuhUsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **List of pre-available styles and prompts**"
      ],
      "metadata": {
        "id": "m0LJwfWYiU_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "style_list = [\n",
        "    {\n",
        "        \"name\": \"(No Style)\",\n",
        "        \"prompt\": \"{prompt}\",\n",
        "        \"negative_prompt\": (\n",
        "            \"longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, blurry, distorted, artifacts\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Anime\",\n",
        "        \"prompt\": (\n",
        "            \"vibrant anime artwork, sharp outlines, vivid colors, detailed characters, dynamic lighting, expressive faces, cinematic compositions, dramatic storytelling, vivid backgrounds, key visual aesthetic, polished designs, studio anime\"\n",
        "        ),\n",
        "        \"negative_prompt\": (\n",
        "            \"blurred, low-quality, flat colors, overexposed lighting, poorly proportioned characters, dull backgrounds, lack of detail, realistic proportions, muted colors, harsh shadows, distorted perspectives, unrefined lines, noise, grain\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Neon\",\n",
        "        \"prompt\": (\n",
        "            \"futuristic cyberpunk scene, glowing neon lights, hues of blue and purple, pink accents, sleek urban designs, towering skyscrapers, tech-enhanced outfits, glowing elements, reflective surfaces, rain-soaked streets, high-tech dystopia, moody atmosphere, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights\"\n",
        "        ),\n",
        "        \"negative_prompt\": (\n",
        "            \"dull colors, natural landscapes, low-tech, medieval themes, low-resolution details, lack of neon glow, warm tones, absence of urban environment, soft lighting, lack of reflections, mundane designs, poorly lit scenes, blurred, noise, grain\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Manga\",\n",
        "        \"prompt\": (\n",
        "            \"highly detailed manga-style artwork, bold black-and-white contrasts, clean linework, dynamic shading, expressive characters, intricate patterns, storytelling focus, dramatic compositions, traditional Japanese manga aesthetic, visually striking panels, detailed expressions, classic manga styles, polished designs\"\n",
        "        ),\n",
        "        \"negative_prompt\": (\n",
        "            \"lack of detail, faint lines, unbalanced contrast, lack of storytelling, inconsistent shading, muted tones, overuse of gray, poor composition, blurred designs, dull visuals, excessive colors, lack of texture, noise, grain\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Digital\",\n",
        "        \"prompt\": (\n",
        "            \"hyper-realistic digital portrait artwork, intricate facial details, luminous skin textures, expressive and captivating eyes, smooth and polished surfaces, soft gradients, dynamic yet subtle lighting, professional digital rendering, highly detailed and stylized character design, artistic precision, visually compelling compositions, painterly yet refined quality\"\n",
        "        ),\n",
        "        \"negative_prompt\": (\n",
        "            \"blurred or smudged details, overly harsh shadows, low resolution, unbalanced lighting, unrealistic or flat expressions, unpolished textures, lack of detail in the eyes, excessive noise or grain, dull or uninspired compositions, overly simplistic designs, lack of sharpness or refinement\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Fantasy\",\n",
        "        \"prompt\": (\n",
        "            \"immersive fantasy artwork, magical landscapes, ethereal lighting, enchanted forests, epic scenes, intricate details, vivid colors, glowing effects, dramatic skies, imaginative worlds, majestic compositions, awe-inspiring designs\"\n",
        "        ),\n",
        "        \"negative_prompt\": (\n",
        "            \"dull colors, lack of detail, low resolution, overly simplistic designs, absence of fantasy elements, muted tones, mundane scenes, poor composition, blurred, noise, lack of imagination, grain, harsh shadows, realistic styles\"\n",
        "        ),\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "RpVPVxyzBjP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Core functions**"
      ],
      "metadata": {
        "id": "5G4Kdvl7irDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nms(x, t, s):\n",
        "    \"\"\"\n",
        "    Performs Non-Maximum Suppression (NMS) on the image.\n",
        "    \"\"\"\n",
        "    x = cv2.GaussianBlur(x.astype(np.float32), (0, 0), s)\n",
        "\n",
        "    f1 = np.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]], dtype=np.uint8)\n",
        "    f2 = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]], dtype=np.uint8)\n",
        "    f3 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=np.uint8)\n",
        "    f4 = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=np.uint8)\n",
        "\n",
        "    y = np.zeros_like(x)\n",
        "\n",
        "    for f in [f1, f2, f3, f4]:\n",
        "        np.putmask(y, cv2.dilate(x, kernel=f) == x, x)\n",
        "\n",
        "    z = np.zeros_like(y, dtype=np.uint8)\n",
        "    z[y > t] = 255\n",
        "    return z\n",
        "\n",
        "\n",
        "def process_sketch(sketch):\n",
        "    \"\"\"\n",
        "    Preprocesses a sketch input into a controlnet-compatible format.\n",
        "    \"\"\"\n",
        "    controlnet_img = np.array(sketch[\"composite\"])\n",
        "    controlnet_img = cv2.cvtColor(controlnet_img, cv2.COLOR_RGB2GRAY)\n",
        "    controlnet_img[controlnet_img > 127] = 255\n",
        "    controlnet_img[controlnet_img <= 127] = 0\n",
        "    return Image.fromarray(controlnet_img)\n",
        "\n",
        "\n",
        "def process_image(image_path):\n",
        "    \"\"\"\n",
        "    Converts an image into a controlnet-compatible scribble.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Image not found or invalid.\")\n",
        "\n",
        "        # Edge detection using HED or similar processor\n",
        "        controlnet_img = hed_processor(image, scribble=False)\n",
        "        controlnet_img = np.array(controlnet_img)\n",
        "\n",
        "        # Apply Gaussian blur and NMS\n",
        "        controlnet_img = cv2.GaussianBlur(controlnet_img, (0, 0), 3)\n",
        "        controlnet_img = nms(controlnet_img, t=100, s=1.0)\n",
        "\n",
        "        # Simulate a human-like sketch\n",
        "        random_val = int(round(random.uniform(0.01, 0.10), 2) * 255)\n",
        "        controlnet_img[controlnet_img > random_val] = 255\n",
        "        controlnet_img[controlnet_img < 255] = 0\n",
        "\n",
        "        return Image.fromarray(controlnet_img)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "jPxO4kIC7VfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_style_to_prompt(style_name, user_prompt):\n",
        "    \"\"\"\n",
        "    Combines the user prompt with the selected style.\n",
        "    \"\"\"\n",
        "    style_data = next(style for style in style_list if style[\"name\"] == style_name)\n",
        "    positive_prompt = f\"{user_prompt}, {style_data['prompt']}\"\n",
        "    negative_prompt = style_data[\"negative_prompt\"]\n",
        "    return positive_prompt, negative_prompt\n",
        "\n",
        "\n",
        "def generate_with_pipeline(controlnet_img, prompt, negative_prompt, width, height):\n",
        "    \"\"\"\n",
        "    Generates an image using the pipeline.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        images = pipe(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            image=controlnet_img,\n",
        "            controlnet_conditioning_scale=1.2,\n",
        "            guidance_scale=7.5,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            num_inference_steps=50,\n",
        "        ).images\n",
        "        return images[0] if images else None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during image generation: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "jb28vb-Si3Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(sketch, user_prompt, selected_style, input_type, image=None, num_steps=25, guidance_scale=7.5, controlnet_conditioning_scale=1.2, seed=0, randomize_seed=True):\n",
        "    \"\"\"\n",
        "    Main function for generating images based on sketch or image input.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if randomize_seed:\n",
        "            seed = random.randint(0, 9999)\n",
        "\n",
        "        if input_type == \"Sketch\":\n",
        "            controlnet_img = process_sketch(sketch)\n",
        "        elif input_type == \"Image\" and image:\n",
        "            controlnet_img = process_image(image)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid input type or missing image.\")\n",
        "\n",
        "        if controlnet_img is None:\n",
        "            raise ValueError(\"Failed to process input.\")\n",
        "\n",
        "        # Resize image for compatibility\n",
        "        controlnet_img = controlnet_img.resize((1024, 1024))\n",
        "\n",
        "        # Prepare prompts\n",
        "        positive_prompt, negative_prompt = apply_style_to_prompt(selected_style, user_prompt)\n",
        "\n",
        "        # Generate and return the image\n",
        "        return generate_with_pipeline(\n",
        "            controlnet_img, positive_prompt, negative_prompt, 1024, 1024\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "efNf2Mu0XhSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradio Interface**"
      ],
      "metadata": {
        "id": "-WBiB2gLjKYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface():\n",
        "    \"\"\"\n",
        "    Gradio interface for the Sketch-to-Image generator with examples.\n",
        "    \"\"\"\n",
        "    with gr.Blocks() as demo:\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                <h1 style=\"text-align: center;\">Advanced Sketch-to-Art Generator</h1>\n",
        "                <p style=\"text-align: center;\">Draw or input an image or sketch, enter your prompt, and see the magic happen!</p>\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        # Input and Output Section\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                with gr.Group():\n",
        "                    input_type = gr.Radio(\n",
        "                        choices=[\"Sketch\", \"Image\"],\n",
        "                        label=\"Input Type\",\n",
        "                        value=\"Sketch\"\n",
        "                    )\n",
        "                    sketch_input = gr.Sketchpad(\n",
        "                        label=\"Draw a sketch\",\n",
        "                        visible=True,\n",
        "                        height=450,\n",
        "                        width=450\n",
        "                    )\n",
        "                    image_input = gr.Image(\n",
        "                        type=\"filepath\",\n",
        "                        label=\"Upload an image\",\n",
        "                        visible=False\n",
        "                    )\n",
        "                    user_prompt = gr.Textbox(label=\"Describe your image\", lines=2)\n",
        "                    style_dropdown = gr.Dropdown(\n",
        "                        label=\"Select Style\",\n",
        "                        choices=[style[\"name\"] for style in style_list]\n",
        "                    )\n",
        "\n",
        "                run_button = gr.Button(\"Generate\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output_image = gr.Image(\n",
        "                    label=\"Generated Image\",\n",
        "                    height=450,\n",
        "                    width=450,\n",
        "                )\n",
        "\n",
        "        # Advanced options with notes about defaults\n",
        "        with gr.Accordion(\"Advanced Options\", open=False):\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                <p><b>Defaults:</b> Steps = 50, Conditioning Scale = 1.2, Guidance = 7.5.</p>\n",
        "                \"\"\"\n",
        "            )\n",
        "            num_steps = gr.Slider(\n",
        "                label=\"Steps\",\n",
        "                minimum=1,\n",
        "                maximum=50,\n",
        "                value=50,\n",
        "                step=1\n",
        "            )\n",
        "            guidance_scale = gr.Slider(\n",
        "                label=\"Guidance\",\n",
        "                minimum=1,\n",
        "                maximum=10,\n",
        "                value=7.5,\n",
        "                step=0.1\n",
        "            )\n",
        "            controlnet_conditioning_scale = gr.Slider(\n",
        "                label=\"Conditioning Scale\",\n",
        "                minimum=0.5,\n",
        "                maximum=5.0,\n",
        "                value=1.2,\n",
        "                step=0.1\n",
        "            )\n",
        "            seed = gr.Slider(\n",
        "                label=\"Seed\",\n",
        "                minimum=0,\n",
        "                maximum=9999,\n",
        "                value=0,\n",
        "                step=1\n",
        "            )\n",
        "            randomize_seed = gr.Checkbox(\n",
        "                label=\"Randomize Seed\",\n",
        "                value=True\n",
        "            )\n",
        "\n",
        "        # Examples Section\n",
        "        examples = [\n",
        "            [\"Image\", \"/content/drive/MyDrive/face.webp\", \"Boy, curly hair, t-shirt\", \"Digital\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/superhero.webp\", \"Superhero in pink armor, cute and lighthearted, kawaii, chibi, pastel colors, whimsical atmosphere\", \"(No Style)\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/grim_reaper.webp\", \"Grim Reaper, bones\", \"Neon\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/fox.webp\", \"Orange Fox sitting with red fruit on head, lighthearted, kawaii, cute, adorable\", \"Anime\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/women.webp\", \"Women sitting in park reading book, trees, \", \"Manga\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/book.webp\", \"Glowing green stone on open book\", \"Fantasy\"],\n",
        "            [\"Image\", \"/content/drive/MyDrive/car.webp\", \"Car driving fast, movie-like composition, film grainy, vignette, highly detailed, high budget, bokeh, cinemascope\", \"(No Style)\"]\n",
        "        ]\n",
        "\n",
        "        gr.Examples(\n",
        "            examples=examples,\n",
        "            inputs=[input_type, image_input, user_prompt, style_dropdown],\n",
        "            label=\"Try these examples\",\n",
        "        )\n",
        "\n",
        "        # Input and output mapping\n",
        "        def toggle_inputs(input_type):\n",
        "            return (\n",
        "                gr.update(visible=input_type == \"Sketch\"),\n",
        "                gr.update(visible=input_type == \"Image\"),\n",
        "            )\n",
        "\n",
        "        input_type.change(\n",
        "            toggle_inputs,\n",
        "            inputs=[input_type],\n",
        "            outputs=[sketch_input, image_input]\n",
        "        )\n",
        "\n",
        "        # Button click handler\n",
        "        run_button.click(\n",
        "            fn=generate_image,\n",
        "            inputs=[\n",
        "                sketch_input, user_prompt, style_dropdown, input_type,\n",
        "                image_input, num_steps, guidance_scale,\n",
        "                controlnet_conditioning_scale, seed, randomize_seed\n",
        "            ],\n",
        "            outputs=[output_image]\n",
        "        )\n",
        "\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "gradio_interface()"
      ],
      "metadata": {
        "id": "2hnWKU_KjNjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}